{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain,ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "sec_key = os.getenv(\"HUGGING_FACE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"deepseek-ai/DeepSeek-R1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(repo_id=repo_id,huggingfacehub_api_token=sec_key, task=\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory( )\n",
    "prompt_template_name = PromptTemplate(\n",
    "        input_variables=[\"cuisine\"],\n",
    "    template=\"i want to open a restaurant for {cuisine} food. suggest me a fancy name for this. just give me a one word of a restaurant name\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHAMMED SHAHID\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "\"Raj\"\n",
      "\n",
      "The name \"Raj\" is a great choice for your Indian restaurant. It has a royal and sophisticated sound to it, fitting for a fancy establishment. Here's how it looks:\n",
      "\n",
      "**Raj**\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm = llm,prompt = prompt_template_name,memory = memory)\n",
    "name = chain.run(\"Indian\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Indian\n",
      "AI: .\n",
      "\n",
      "\"Raj\"\n",
      "\n",
      "The name \"Raj\" is a great choice for your Indian restaurant. It has a royal and sophisticated sound to it, fitting for a fancy establishment. Here's how it looks:\n",
      "\n",
      "**Raj**\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "convo = ConversationChain(llm =llm)\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHAMMED SHAHID\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm glad you're interested in food! To provide the best answer, could you please list the cuisines you're considering?\n"
     ]
    }
   ],
   "source": [
    "response = convo.run(\"which is the best is the best cuisine from the given\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
